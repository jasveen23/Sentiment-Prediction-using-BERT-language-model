{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INM 706 Coursework Code\n",
    "# Sentiment Prediction of drug reviews dataset using BERT (Bidirectional Encoder Representation from Transformers)\n",
    "## By: Elisabeta Monica Furdui: 190045971 and Jasveen Kaur: 190020638 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset Interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0826 15:36:17.702810  3292 file_utils.py:38] PyTorch version 1.1.0 available.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import csv\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer, AdamW, get_linear_schedule_with_warmup, AutoTokenizer, AutoModel, AutoModelWithLMHead\n",
    "\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Raw Train and Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('./drugsCom_raw/drugsComTrain_raw.tsv', delimiter='\\t',encoding='utf-8')\n",
    "df_test = pd.read_csv('./drugsCom_raw/drugsComTest_raw.tsv', delimiter='\\t',encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>drugName</th>\n",
       "      <th>condition</th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>date</th>\n",
       "      <th>usefulCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>206461</td>\n",
       "      <td>Valsartan</td>\n",
       "      <td>Left Ventricular Dysfunction</td>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>May 20, 2012</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>95260</td>\n",
       "      <td>Guanfacine</td>\n",
       "      <td>ADHD</td>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>April 27, 2010</td>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>92703</td>\n",
       "      <td>Lybrel</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>December 14, 2009</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>138000</td>\n",
       "      <td>Ortho Evra</td>\n",
       "      <td>Birth Control</td>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>November 3, 2015</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35696</td>\n",
       "      <td>Buprenorphine / naloxone</td>\n",
       "      <td>Opiate Dependence</td>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>November 27, 2016</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                  drugName                     condition  \\\n",
       "0      206461                 Valsartan  Left Ventricular Dysfunction   \n",
       "1       95260                Guanfacine                          ADHD   \n",
       "2       92703                    Lybrel                 Birth Control   \n",
       "3      138000                Ortho Evra                 Birth Control   \n",
       "4       35696  Buprenorphine / naloxone             Opiate Dependence   \n",
       "\n",
       "                                              review  rating  \\\n",
       "0  \"It has no side effect, I take it in combinati...     9.0   \n",
       "1  \"My son is halfway through his fourth week of ...     8.0   \n",
       "2  \"I used to take another oral contraceptive, wh...     5.0   \n",
       "3  \"This is my first time using any form of birth...     8.0   \n",
       "4  \"Suboxone has completely turned my life around...     9.0   \n",
       "\n",
       "                date  usefulCount  \n",
       "0       May 20, 2012           27  \n",
       "1     April 27, 2010          192  \n",
       "2  December 14, 2009           17  \n",
       "3   November 3, 2015           10  \n",
       "4  November 27, 2016           37  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataset sample\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 161297 entries, 0 to 161296\n",
      "Data columns (total 7 columns):\n",
      "Unnamed: 0     161297 non-null int64\n",
      "drugName       161297 non-null object\n",
      "condition      160398 non-null object\n",
      "review         161297 non-null object\n",
      "rating         161297 non-null float64\n",
      "date           161297 non-null object\n",
      "usefulCount    161297 non-null int64\n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 8.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 53766 entries, 0 to 53765\n",
      "Data columns (total 7 columns):\n",
      "Unnamed: 0     53766 non-null int64\n",
      "drugName       53766 non-null object\n",
      "condition      53471 non-null object\n",
      "review         53766 non-null object\n",
      "rating         53766 non-null float64\n",
      "date           53766 non-null object\n",
      "usefulCount    53766 non-null int64\n",
      "dtypes: float64(1), int64(2), object(4)\n",
      "memory usage: 2.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting the ratings to sentiment values and adding a new column named 'sentiment', where: Postive: 2, Neutral: 1, Negative: 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sentiment(rat):\n",
    "    rat = int(rat)\n",
    "    if rat <= 3:\n",
    "        return 0\n",
    "    elif rat == 4 or rat == 7:\n",
    "        return 1\n",
    "    else: \n",
    "        return 2\n",
    "\n",
    "df_train['sentiment'] = df_train.rating.apply(to_sentiment)\n",
    "df_test['sentiment'] = df_test.rating.apply(to_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining a function to preprocess the reviews using regex library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_preprocessing(text):\n",
    "    # Remove '@name'\n",
    "    text = text.replace('\"',\"\")\n",
    "    \n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "    \n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Remove '&#039;'\n",
    "    text = re.sub(r'&#039;',\"'\", text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_train['review'])):\n",
    "    text_preprocessing(df_train['review'][i])\n",
    "for i in range(len(df_test['review'])):\n",
    "    text_preprocessing(df_test['review'][i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataframes after removing extra columns and splitting the train data into train and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dropping the columns that are not needed\n",
    "train = df_train.drop(['Unnamed: 0','drugName','condition','date','rating','usefulCount'], axis = 1)\n",
    "test = df_test.drop(['Unnamed: 0','drugName','condition','date','rating','usefulCount'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\"It has no side effect, I take it in combinati...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"My son is halfway through his fourth week of ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"I used to take another oral contraceptive, wh...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"This is my first time using any form of birth...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>\"Suboxone has completely turned my life around...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  \"It has no side effect, I take it in combinati...          2\n",
       "1  \"My son is halfway through his fourth week of ...          2\n",
       "2  \"I used to take another oral contraceptive, wh...          2\n",
       "3  \"This is my first time using any form of birth...          2\n",
       "4  \"Suboxone has completely turned my life around...          2"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.sample(frac=0.8, random_state=1)\n",
    "val_data = train[~train.index.isin(train_data.index)]\n",
    "test_data = test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative 0: 27958\n",
      "Neutral 1: 11590\n",
      "Positive 2: 89490\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x193a6c5e2e8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_count = train_data.sentiment.value_counts()\n",
    "print('Negative 0:', sentiment_count[0])\n",
    "print('Neutral 1:', sentiment_count[1])\n",
    "print('Positive 2:', sentiment_count[2])\n",
    "\n",
    "sentiment_count.plot(kind='bar', title='Samples under each sentiment in train set', color = list('rgb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative 0: 11838\n",
      "Neutral 1: 4750\n",
      "Positive 2: 37178\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x193a6bdb208>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_count = test_data.sentiment.value_counts()\n",
    "print('Negative 0:', sentiment_count[0])\n",
    "print('Neutral 1:', sentiment_count[1])\n",
    "print('Positive 2:', sentiment_count[2])\n",
    "\n",
    "sentiment_count.plot(kind='bar', title='Samples under each sentiment in test set', color = list('rgb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative 0: 7105\n",
      "Neutral 1: 2878\n",
      "Positive 2: 22276\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x193a6c0eda0>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAEFCAYAAAAIZiutAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAF31JREFUeJzt3Xu0XWV97vHvUxBFRUEJFCEQq/ECapFGoKc6Sk8rBNTiGaNYPCoRL1Grx9rBsVpPWyxYL+NYW+mxWqwoXpFja0krCCneTkWU4IVLAUkRSQxCIIAgilx+54/5bl3sdyV7JztkJfD9jLHGXuudc835m5e1njnfOffeqSokSRr1S5MuQJK09TEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw2Erl+StST4+6To2JEklefyk69iQrbHGJC9Kcs6k6xgnyQeS/NkWnueCtp22b6/PSrJkNuNuwrzekuQf5lLv/Z3hsB5JnpnkvCS3JFmX5KtJnjHpurRtGvdlVlWfqKpDJ1DLIUlWb2icqnp1VZ24pWpaTw2HV9Wpc53OuOWtqrdX1SvmOu3NJclHkrxt0nWM2qTUvb9L8gjgX4HXAKcDOwDPAu6YZF33N0m2r6q7Jl2HpDGqyse0B7AIuHkDwx8HfAG4EbgB+ASw88jwq4E3AhcBPwY+BOwOnAXcCvwbsEsbdwFQwFJgDXAtcNzItN4KfHzk9cHAecDNwHeAQ0aGvRS4qs3je8CL1lP/R4C3jbw+BFg9rf7/2eq/Bfg08JCR4W9sda4BXtbqf3wb9mDg3cA1wHXAB4AdR+cDvAn4IfCx9dT3MuAy4CbgbGCfkWHvBVYBPwIuBJ41Mmw74C3Af7Z1cCEwvw0r4NXAlW267wOynvkfCKxo87gOeM8s1/+XgBOBr7b5nwPs2oZd02q4rT1+vW2vfx95fwF/0Gq8tU3rccDXWi2nAzuMjP9c4NutlvOAp820DYGHAT8B7hmp5TEb2kdGtttxwPVt2x+7nnV3NLBiWtsfAcva8+cA32rLswp468h4C9o62H5kfb5iZNu+m+HzdhXw2mnjHtv2mVvb8Fe19rHLS/+5+l3g0rYuvwQ8ebafh2nL+njgy228G4BPjwx7ErAcWAdcAbygtS8F7gR+1ur7l0l/B1aV4bCeDfwIhi/+U4HDaV/k03aAZzN8Ec4DvgL8zbSd6XyGQNizfaC+CTy9vecLwPHTPhCfajvyU4G1wO+04T/fidu0bgSOYOgSfHZ7Pa+990fAE9u4ewD7rWf5PsLM4fCN9iF6VPvQvboNW8zwhfmUNs9Pcu9w+BtgWXvfTsC/AO8Ymc9dwLvaethxTG3PB1YCT2Y4s/1T4LyR4S8GHt2GHccQMg9pw94IXAw8EQjwq8Cj27BiOBvcGdi7rePF61k/XwNe0p4/HDh4pvXfhn+JIZieAOzYXr9z2nbefmQ+L6UPh2UM+99+DGeq5wK/AjwS+A9gSRv3AIb96iCGL84lbbs9eBbb8F7be6Z9ZGS7nQA8qC3/7Uz7XLRxH8rwBb1wpO0C4OiRaT21rb+nMexLzx+3jrh3OLwauByY35bni9PGfQ5DkAb4zVbfAetbXu79uXoCw0Hcs9vy/THDPrjDTOtyzPJ/CvhfbfkeAjyztT+MIQyPZdh3D2AIj/3GfSa3hofXHMaoqh8Bz2TY+T4IrE2yLMnubfjKqlpeVXdU1VrgPQw75Ki/rarrquoHwP8Dvl5V36qqO4DPMgTFqL+oqh9X1cXAh4EXjintxcCZVXVmVd1TVcsZjnCPaMPvAZ6SZMequraqLp3DajipqtZU1TqGL/j9W/sLgA9X1SVV9WOGDxkASQK8EvijqlpXVbcCb2c4mpxyD0Mw3lFVPxkz31cxhMllNXQ5vR3YP8k+AFX18aq6saruqqq/YgiZJ7b3vgL406q6ogbfqaobR6b9zqq6uaquYfhy2Z/x7gQen2TXqrqtqs5v7TOtf9q6+W5bttM3MI/1eVdV/ahtu0uAc6rqqqq6heHMc2q/eSXw91X19aq6u4a++TsYzmymrG8bboo7gROq6s6qOpPhCPeJ00eqqtuBM2j7b5KFDEfMy9rwL1XVxW39XcTwZTr9szPOCxgOwFa15XnHtPl+rqr+s233LzOctT1rlsv2+8Dn2mf6ToYzlB2B/zIyzmzX5Z3APgxnYz+tqn9v7c8Frq6qD7d995vAPwK/N8satzjDYT3al9NLq2ovhqPkxzAcFZNktySnJflBkh8BHwd2nTaJ60ae/2TM64dPG3/VyPPvt/lNtw9wVJKbpx4MIbZH+6L+fYYjrGuTfC7JkzZmmaf54cjz20fqfcyYWqfMYzhyvHCkvs+39ilrq+qnG5jvPsB7R96/juFocE+AJMcluazdKHAzwxH11Lqfz3DkvrHLNN3LGY4mL09yQZLnjtQ2dv1vwjzWZ7b7zT7AcdNqmc+995u51jLqxrr39aENTe+T/OLg5r8D/9xCgyQHJflikrVJbmHYX6d/dsbZ0H5HksOTnN9uHrmZIbBnM92paf98elV1T5vXniPjzHZd/jHD/vqNJJcmeVlr3wc4aNr2ehHwy7OscYszHGahqi5nOO17Smt6B8NZxdOq6hEMR5SZ42zmjzzfm6E/f7pVDP30O488HlZV72x1nl1Vz2b4srqc4axnnB8zfIlP2Zgd9NoxtU65geELbL+R+h5ZVaMfpJn+DPAqhv7i0WXcsarOS/IshusVL2Do0tiZoW83I+993EYsy1hVdWVVvRDYjaEL7DNJproF1rv+Z5rsXOuaZhXwl9NqeWhVfWoCtUx3DrBrkv0ZQuKTI8M+yXAWMb+qHslwTWo2n5317ndJHsxwFP5uYPe2X5w5Mt2ZlncNw5f31PTS5vWDWdR1L1X1w6p6ZVU9huEs+O/aLdSrgC9P214Pr6rXzLLGLc5wGCPJk9oR6l7t9XyGnXyqe2EnhtPqm5PsydDXPVd/luShSfZj6Jf89JhxPg48L8lhSbZL8pB2m95eSXZP8rvtS+yOVt/d65nXt4EjkjwqyS8Db9iIOk8HXppk3yQPBY6fGtCOuD4I/HWS3QCS7JnksI2Y/geAP2nrgSSPTHJUG7YTQ9/3WmD7JH/O0D8/5R+AE5MszOBpSR69EfOmzfPFSea15bm5Nd/NBtb/LCa7lqFL7Vc2tp71+CDw6nYkniQPS/KcJDvN4r3XAY9O8sjNVMu9tDOMzwD/m6GPfvnI4J2AdVX10yQHMpxZzMbpwOvbvr4L8OaRYTswdC+uBe5KcjgweovwTMt7OvCcJL+d5EEM17LuYLjIv1GSHDWyP9zE8KV/N8P1rickeUmSB7XHM5I8eaTGzbVvbBaGw3i3Mlzo+3qSHzOEwiUMOw3AXzBcULoF+BzwT5thnl9muAh2LvDuqup+OaqqVgFHMtyRs5bhaOSNDNvxl1p9axi6Yn6T4c6XcT7GcKfN1QxHeeOCaKyqOouhe+0Lrd4vTBvlTa39/Nbl9m+M6ZvewPQ/y3C0flp7/yUMNwXAcOfSWcB3GboBfsq9uxrew/BBP4fh4vyHGPqON9Zi4NIktzHcHXV06z/e0PqfabluB/4S+GrrVjh4pvfMML0VDNcd/g/Dl9BKhgvcs3nv5Qx9/Ve1WsZ1Yc7VJ4HfAf7vtO6oPwBOSHIr8OcM22s2Psiw/b/DcHPHzz9z7drW69u0bmIInGUjwze4vFV1BcPZ/98ynP0+D3heVf1s1kv7C89g+N64rdXwh1X1vVbjoQzX39YwdFNN3ZgBw766b6vvnzdhvptdqra6s5kHlCQLGG47fVB5z7+krYRnDpKkjuEgSerYrSRJ6njmIEnqGA6SpM42+1dZd91111qwYMGky5CkbcqFF154Q1XNm2m8bTYcFixYwIoVKyZdhiRtU5J8f+ax7FaSJI1hOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOtvsL8FtcZnrfwHdivnHFyVN45mDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKljOEiSOoaDJKkzYzgkmZ/ki0kuS3Jpkj9s7Y9KsjzJle3nLq09SU5KsjLJRUkOGJnWkjb+lUmWjLT/WpKL23tOSu7P/3ZNkrZ+szlzuAs4rqqeDBwMvDbJvsCbgXOraiFwbnsNcDiwsD2WAu+HIUyA44GDgAOB46cCpY2zdOR9i+e+aJKkTTVjOFTVtVX1zfb8VuAyYE/gSODUNtqpwPPb8yOBj9bgfGDnJHsAhwHLq2pdVd0ELAcWt2GPqKqvVVUBHx2ZliRpAjbqmkOSBcDTga8Du1fVtTAECLBbG21PYNXI21a3tg21rx7TPm7+S5OsSLJi7dq1G1O6JGkjzDockjwc+EfgDVX1ow2NOqatNqG9b6w6uaoWVdWiefPmzVSyJGkTzSockjyIIRg+UVX/1Jqva11CtJ/Xt/bVwPyRt+8FrJmhfa8x7ZKkCZnN3UoBPgRcVlXvGRm0DJi642gJcMZI+zHtrqWDgVtat9PZwKFJdmkXog8Fzm7Dbk1ycJvXMSPTkiRNwPazGOc3gJcAFyf5dmt7C/BO4PQkLweuAY5qw84EjgBWArcDxwJU1bokJwIXtPFOqKp17flrgI8AOwJntYckaUIy3CC07Vm0aFGtWLFiy83w/vyrF9voPiBp4yW5sKoWzTSevyEtSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSerMGA5JTklyfZJLRtremuQHSb7dHkeMDPuTJCuTXJHksJH2xa1tZZI3j7Q/NsnXk1yZ5NNJdticCyhJ2nizOXP4CLB4TPtfV9X+7XEmQJJ9gaOB/dp7/i7Jdkm2A94HHA7sC7ywjQvwrjathcBNwMvnskCSpLmbMRyq6ivAullO70jgtKq6o6q+B6wEDmyPlVV1VVX9DDgNODJJgP8KfKa9/1Tg+Ru5DJKkzWwu1xxel+Si1u20S2vbE1g1Ms7q1ra+9kcDN1fVXdPaJUkTtKnh8H7gccD+wLXAX7X2jBm3NqF9rCRLk6xIsmLt2rUbV7EkadY2KRyq6rqquruq7gE+yNBtBMOR//yRUfcC1myg/QZg5yTbT2tf33xPrqpFVbVo3rx5m1K6JGkWNikckuwx8vK/AVN3Mi0Djk7y4CSPBRYC3wAuABa2O5N2YLhovayqCvgi8Hvt/UuAMzalJknS5rP9TCMk+RRwCLBrktXA8cAhSfZn6AK6GngVQFVdmuR04D+Au4DXVtXdbTqvA84GtgNOqapL2yzeBJyW5G3At4APbbalkyRtkgwH79ueRYsW1YoVK7bcDDPu8sj9xDa6D0jaeEkurKpFM43nb0hLkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpYzhIkjqGgySpM2M4JDklyfVJLhlpe1SS5UmubD93ae1JclKSlUkuSnLAyHuWtPGvTLJkpP3Xklzc3nNSkmzuhZQkbZzZnDl8BFg8re3NwLlVtRA4t70GOBxY2B5LgffDECbA8cBBwIHA8VOB0sZZOvK+6fOSJG1hM4ZDVX0FWDet+Ujg1Pb8VOD5I+0frcH5wM5J9gAOA5ZX1bqquglYDixuwx5RVV+rqgI+OjItSdKEbOo1h92r6lqA9nO31r4nsGpkvNWtbUPtq8e0j5VkaZIVSVasXbt2E0uXJM1kc1+QHne9oDahfayqOrmqFlXVonnz5m1iiZKkmWxqOFzXuoRoP69v7auB+SPj7QWsmaF9rzHtkqQJ2tRwWAZM3XG0BDhjpP2YdtfSwcAtrdvpbODQJLu0C9GHAme3YbcmObjdpXTMyLQkSROy/UwjJPkUcAiwa5LVDHcdvRM4PcnLgWuAo9roZwJHACuB24FjAapqXZITgQvaeCdU1dRF7tcw3BG1I3BWe0iSJijDTULbnkWLFtWKFSu23Azvz79+sY3uA5I2XpILq2rRTOP5G9KSpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpM72ky5Auq/lLzLpEu5TdXxNugTdD3nmIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqGA6SpI7hIEnqzCkcklyd5OIk306yorU9KsnyJFe2n7u09iQ5KcnKJBclOWBkOkva+FcmWTK3RZIkzdXmOHP4rarav6oWtddvBs6tqoXAue01wOHAwvZYCrwfhjABjgcOAg4Ejp8KFEnSZNwX3UpHAqe256cCzx9p/2gNzgd2TrIHcBiwvKrWVdVNwHJg8X1QlyRpluYaDgWck+TCJEtb2+5VdS1A+7lba98TWDXy3tWtbX3tkqQJmev/kP6NqlqTZDdgeZLLNzDuuH/kWxto7ycwBNBSgL333ntja5UkzdKczhyqak37eT3wWYZrBte17iLaz+vb6KuB+SNv3wtYs4H2cfM7uaoWVdWiefPmzaV0SdIGbHI4JHlYkp2mngOHApcAy4CpO46WAGe058uAY9pdSwcDt7Rup7OBQ5Ps0i5EH9raJEkTMpdupd2BzyaZms4nq+rzSS4ATk/ycuAa4Kg2/pnAEcBK4HbgWICqWpfkROCCNt4JVbVuDnVJkuZok8Ohqq4CfnVM+43Ab49pL+C165nWKcApm1qLJGnz8jekJUkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEkdw0GS1DEcJEmduf4PaUm6T2Xcf5m/H6madAXjeeYgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkjuEgSeoYDpKkzlYTDkkWJ7kiycokb550PZL0QLZVhEOS7YD3AYcD+wIvTLLvZKuSpAeurSIcgAOBlVV1VVX9DDgNOHLCNUnSA9b2ky6g2RNYNfJ6NXDQ9JGSLAWWtpe3JbliC9Q2KbsCN2yROSVbZDYPIFtu2wF5q9tvM9uy22/Lb759ZjPS1hIO41ZPdQ1VJwMn3/flTF6SFVW1aNJ1aOO57bZtbr/B1tKttBqYP/J6L2DNhGqRpAe8rSUcLgAWJnlskh2Ao4FlE65Jkh6wtopupaq6K8nrgLOB7YBTqurSCZc1aQ+I7rP7Kbfdts3tB6Sq69qXJD3AbS3dSpKkrYjhIEnqGA6SpM5WcUH6gS7Jkxh+EfDrVXXbSPviqvr85CrTbLTtdyTDNiyG27CXVdVlEy1MmgPPHCYsyeuBM4D/AVySZPTPhrx9MlVptpK8ieHPvQT4BsNt2QE+5R+Q3LYlOXbSNUySdytNWJKLgV+vqtuSLAA+A3ysqt6b5FtV9fSJFqgNSvJdYL+qunNa+w7ApVW1cDKVaa6SXFNVe0+6jkmxW2nytpvqSqqqq5McAnwmyT6M/7Mi2rrcAzwG+P609j3aMG3Fkly0vkHA7luylq2N4TB5P0yyf1V9G6CdQTwXOAV46mRL0yy8ATg3yZX84o9H7g08HnjdxKrSbO0OHAbcNK09wHlbvpyth+EweccAd402VNVdwDFJ/n4yJWm2qurzSZ7A8Gfn92T4UlkNXFBVd0+0OM3GvwIPnzo4G5XkS1u+nK2H1xwkSR3vVpIkdQwHSVLHcJAkdQwHSVLHcJAkdf4/VsvG7bPiNS4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentiment_count = val_data.sentiment.value_counts()\n",
    "print('Negative 0:', sentiment_count[0])\n",
    "print('Neutral 1:', sentiment_count[1])\n",
    "print('Positive 2:', sentiment_count[2])\n",
    "\n",
    "sentiment_count.plot(kind='bar', title='Samples under each sentiment in validation set', color = list('rgb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bert specific preprocessing: \n",
    "Using encode_plus to preprocess the reviews: Tokenize using BertTokenizer ('bert-base-cased'), add special tokens ( [CLS], [PAD], [SEP], [UNK] ), truncate the reviews to a maximum length of 512 and return the attention masks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0826 15:36:30.281196  3292 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-v1.1/config.json from cache at C:\\Users\\adbb083\\.cache\\torch\\transformers\\f8aa55d48600e63a39633cbb1bd933404d161174c7cabf1b4059b574404d6c19.08d27a67caf57f599c177c8e7fefc24d3e2f9a4e6ed2feca12f613f48c66ce07\n",
      "I0826 15:36:30.281196  3292 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I0826 15:36:30.296856  3292 tokenization_utils.py:925] Model name 'dmis-lab/biobert-v1.1' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'dmis-lab/biobert-v1.1' is a path, a model identifier, or url to a directory containing tokenizer files.\n",
      "I0826 15:36:31.828379  3292 tokenization_utils.py:1011] loading file https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-v1.1/vocab.txt from cache at C:\\Users\\adbb083\\.cache\\torch\\transformers\\788ec7f94fa5412d56872a6c92079f8f48fb3dfbb1994fdeb251302999562180.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n",
      "I0826 15:36:31.843715  3292 tokenization_utils.py:1011] loading file https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-v1.1/added_tokens.json from cache at None\n",
      "I0826 15:36:31.843715  3292 tokenization_utils.py:1011] loading file https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-v1.1/special_tokens_map.json from cache at C:\\Users\\adbb083\\.cache\\torch\\transformers\\29bcdc1d6651ef6310f8743ffb91ebec1135819dde9448330d5c636dc614425f.275045728fbf41c11d3dae08b8742c054377e18d92cc7b72b6351152a99b64e4\n",
      "I0826 15:36:31.843715  3292 tokenization_utils.py:1011] loading file https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-v1.1/tokenizer_config.json from cache at C:\\Users\\adbb083\\.cache\\torch\\transformers\\026b114b2c81e958018d6178d7a172b0ecc5db56f6f8923f0679696c4e09a0ff.33188cc140c92703fe59093b4841dbac6ef481e1a8ab71edfbef8649b9c44029\n"
     ]
    }
   ],
   "source": [
    "# Loading the bert tokenizers for different domain Bert models\n",
    "\n",
    "#tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "#tokenizer = AutoTokenizer.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"dmis-lab/biobert-v1.1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[UNK] 100\n",
      "[SEP] 102\n",
      "[CLS] 101\n",
      "[PAD] 0\n"
     ]
    }
   ],
   "source": [
    "#Special tokens used by BERT\n",
    "\n",
    "print(tokenizer.unk_token, tokenizer.unk_token_id)\n",
    "print(tokenizer.sep_token, tokenizer.sep_token_id)\n",
    "print(tokenizer.cls_token, tokenizer.cls_token_id)\n",
    "print(tokenizer.pad_token, tokenizer.pad_token_id)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Bert_specific_preprocessing(Dataset):\n",
    "\n",
    "    def __init__(self, reviews, targets, tokenizer, max_len):\n",
    "        self.reviews = reviews\n",
    "        self.targets = targets\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.reviews)\n",
    "  \n",
    "    def __getitem__(self, item):\n",
    "        review = str(self.reviews[item])\n",
    "        target = self.targets[item]\n",
    "\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "        review, #= text_preprocessing(review),\n",
    "        add_special_tokens = True,\n",
    "        max_length = self.max_len,\n",
    "        return_token_type_ids = False,\n",
    "        pad_to_max_length = True,\n",
    "        return_attention_mask = True,\n",
    "        return_tensors = 'pt')\n",
    "\n",
    "        return {'review_text': review,\n",
    "        'input_ids': encoding['input_ids'].flatten(),\n",
    "        'attention_mask': encoding['attention_mask'].flatten(),\n",
    "        'targets': torch.tensor(target, dtype=torch.long)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Pytorch Dataloader to load the preprocessed dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data_loader(df, tokenizer, max_len, batch_size):\n",
    "    ds = Bert_specific_preprocessing(reviews=df.review.to_numpy(),\n",
    "        targets = df.sentiment.to_numpy(),\n",
    "        tokenizer = tokenizer,\n",
    "        max_len = max_len)\n",
    "\n",
    "    return DataLoader(ds,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=0)\n",
    "\n",
    "BATCH_SIZE = 16\n",
    "MAX_LEN = 512\n",
    "\n",
    "train_data_loader = create_data_loader(train_data[:10000], tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "val_data_loader = create_data_loader(val_data[:8000], tokenizer, MAX_LEN, BATCH_SIZE)\n",
    "test_data_loader = create_data_loader(test_data[:8000], tokenizer, MAX_LEN, BATCH_SIZE)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model and Custom Functionality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pretrained BERT models used: Bert Base Cased, BioClinicalBert and BioBert "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0826 15:36:32.374751  3292 configuration_utils.py:285] loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/dmis-lab/biobert-v1.1/config.json from cache at C:\\Users\\adbb083\\.cache\\torch\\transformers\\f8aa55d48600e63a39633cbb1bd933404d161174c7cabf1b4059b574404d6c19.08d27a67caf57f599c177c8e7fefc24d3e2f9a4e6ed2feca12f613f48c66ce07\n",
      "I0826 15:36:32.374751  3292 configuration_utils.py:321] Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertModel\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 28996\n",
      "}\n",
      "\n",
      "I0826 15:36:32.437570  3292 modeling_utils.py:617] loading weights file https://cdn.huggingface.co/dmis-lab/biobert-v1.1/pytorch_model.bin from cache at C:\\Users\\adbb083\\.cache\\torch\\transformers\\a5ea36102a9f4213c56a03820049979ab9dfc8c2c8e63c20095e69050c8b3e2c.1a16d1ac9f74d161ec6db0dad3d9eebd95872ad73fc70c8fc92bffc89cf0b84c\n"
     ]
    }
   ],
   "source": [
    "#bert_model = BertModel.from_pretrained('bert-base-cased')\n",
    "#bert_model = AutoModel.from_pretrained(\"emilyalsentzer/Bio_ClinicalBERT\")\n",
    "bert_model = AutoModel.from_pretrained(\"dmis-lab/biobert-v1.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT with 2 Linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Sentiment(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(BERT_Sentiment, self).__init__()\n",
    "        \n",
    "        self.bert = bert_model\n",
    "        \n",
    "        self.linear1 = nn.Linear(768, 512)\n",
    "        self.drop = nn.Dropout(p=0.3)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        self.out = nn.Linear(512, 3)\n",
    "  \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \n",
    "        _, pooled_output = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        \n",
    "        x = self.linear1(pooled_output)\n",
    "        x = self.relu(x)\n",
    "        x = self.drop(x)\n",
    "        output = self.out(x)\n",
    "        \n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT with 2 GRU layers and one linear layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERTGRU_Sentiment(nn.Module):\n",
    "\n",
    "    def __init__(self): \n",
    "        super(BERTGRU_Sentiment, self).__init__()          \n",
    "        \n",
    "        self.bert = bert_model\n",
    "        \n",
    "        embedding_dim = bert_model.config.to_dict()['hidden_size']\n",
    "        \n",
    "        self.rnn = nn.GRU(embedding_dim,\n",
    "                          512,\n",
    "                          num_layers = 1,\n",
    "                          bidirectional = True,\n",
    "                          batch_first = True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        self.out = nn.Linear(512 * 2, 3)\n",
    "        \n",
    "        \n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            embedded = self.bert(input_ids=input_ids, attention_mask=attention_mask)[0]\n",
    "        _, hidden = self.rnn(embedded)\n",
    "\n",
    "        if self.rnn.bidirectional:\n",
    "            hidden = self.dropout(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1))\n",
    "        else:\n",
    "            hidden = self.dropout(hidden[-1,:,:])\n",
    "\n",
    "        output = self.out(hidden)\n",
    "        \n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Evaluation function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, data_loader, loss_fn, optimizer, device, scheduler, n_examples):\n",
    "    model = model.train()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    for d in data_loader:\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        targets = d[\"targets\"].to(device)\n",
    "\n",
    "        pred = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        #pred = F.softmax(pred, dim = 1)\n",
    "        loss = loss_fn(pred, targets)\n",
    "        pred_val = torch.argmax(pred, dim = 1).to(device)\n",
    "        correct_predictions += torch.sum(pred_val == targets)\n",
    "\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)\n",
    "\n",
    "def eval_model(model, data_loader, loss_fn, device, n_examples):\n",
    "    model = model.eval()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for d in data_loader:\n",
    "            \n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "\n",
    "            pred = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            #pred = F.softmax(pred, dim = 1)\n",
    "            loss = loss_fn(pred, targets)\n",
    "            pred_val = torch.argmax(pred, dim = 1).to(device)\n",
    "            correct_predictions += torch.sum(pred_val == targets)\n",
    "            \n",
    "            losses.append(loss.item())\n",
    "\n",
    "    return correct_predictions.double() / n_examples, np.mean(losses)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 6\n",
    "\n",
    "class_names = ['negative', 'neutral', 'positive']\n",
    "total_steps = len(train_data_loader) * EPOCHS\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "\n",
    "best_accuracy = 0\n",
    "t_acc = []\n",
    "t_loss =[]\n",
    "v_loss = []\n",
    "v_acc = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT with 2 linear layers: model 1\n",
    "\n",
    "model1 = BERT_Sentiment()\n",
    "model1 = model1.to(device)\n",
    "\n",
    "#optimizer1 = torch.optim.RMSprop(model1.parameters(), lr=2e-5)\n",
    "optimizer1 = AdamW(model1.parameters(), lr=2e-5, correct_bias=False)\n",
    "scheduler1 = get_linear_schedule_with_warmup(optimizer1, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BERT with GRU layer: model 2\n",
    "\n",
    "model2 = BERTGRU_Sentiment()\n",
    "model2 = model2.to(device)\n",
    "\n",
    "#optimizer2 = torch.optim.RMSprop(model2.parameters(), lr=2e-5)\n",
    "optimizer2 = AdamW(model2.parameters(), lr=2e-5, correct_bias=False)\n",
    "scheduler2 = get_linear_schedule_with_warmup(optimizer2, num_warmup_steps=0, num_training_steps=total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "start_time = time.time()\n",
    "for epoch in range(EPOCHS):\n",
    "\n",
    "    print(\"Epoch\", epoch +1)\n",
    "\n",
    "    train_acc, train_loss = train_model(model1, train_data_loader, loss_fn, optimizer1, device, scheduler1, len(train_data[:10000]))\n",
    "    print(\"Train loss:\", \"{:.3f}\".format(train_loss), \"| Train accuracy\", \"{:.2f}\".format(train_acc*100),\"%\")\n",
    "    \n",
    "    val_acc, val_loss = eval_model(model1, val_data_loader, loss_fn, device, len(val_data[:8000]))\n",
    "    print(\"Val loss:\", \"{:.3f}\".format(val_loss), \"| Val accuracy\", \"{:.2f}\".format(val_acc*100),\"%\")\n",
    "    \n",
    "    print(\"Time: {}\".format(time.strftime(\"%Hh %Mm %Ss\", time.gmtime(time.time() - start_time))))\n",
    "    print()\n",
    "    t_acc.append(train_acc)\n",
    "    t_loss.append(train_loss)\n",
    "    v_loss.append(val_loss)\n",
    "    v_acc.append(val_acc)\n",
    "    \n",
    "    pickle.dump(t_acc, open('./t_acc.pickle','wb'))\n",
    "    pickle.dump(v_acc, open('./v_acc.pickle','wb'))\n",
    "    pickle.dump(t_loss, open('./t_loss.pickle','wb'))\n",
    "    pickle.dump(v_loss, open('./v_loss.pickle','wb'))\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "        torch.save(model1.state_dict(), 'LINEAR_BioBert.pt')\n",
    "        best_accuracy = val_acc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating the performance of the trained model on test dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading the pretrained custom model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = BERT_Sentiment()\n",
    "model1.load_state_dict(torch.load('./LINEAR_BioBert/LINEAR_BioBert.pt', map_location = device))\n",
    "model1 = model1.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.516 | Test Accuracy 81.08 %\n"
     ]
    }
   ],
   "source": [
    "test_acc, test_loss = eval_model(model1, test_data_loader, loss_fn, device, len(test_data[:8000]))\n",
    "print(\"Test loss:\", \"{:.3f}\".format(test_loss), \"| Test Accuracy\", \"{:.2f}\".format(test_acc*100),\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction on Test data and individual reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Defining a function to predict the sentiment of test dataset and individual reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, data_loader):\n",
    "    model = model.eval()\n",
    "  \n",
    "    review_texts = []\n",
    "    predictions = []\n",
    "    prediction_probs = []\n",
    "    real_values = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for d in data_loader:\n",
    "\n",
    "            texts = d[\"review_text\"]\n",
    "            input_ids = d[\"input_ids\"].to(device)\n",
    "            attention_mask = d[\"attention_mask\"].to(device)\n",
    "            targets = d[\"targets\"].to(device)\n",
    "            \n",
    "            pred = model(input_ids=input_ids,\n",
    "            attention_mask=attention_mask)\n",
    "\n",
    "            pred_val = torch.argmax(pred, dim = 1).to(device)\n",
    "            preds = pred_val \n",
    "            probs = F.softmax(pred, dim=1)\n",
    "\n",
    "            review_texts.extend(texts)\n",
    "            predictions.extend(preds)\n",
    "            prediction_probs.extend(probs)\n",
    "            real_values.extend(targets)\n",
    "\n",
    "    predictions = torch.stack(predictions).cpu()\n",
    "    prediction_probs = torch.stack(prediction_probs).cpu()\n",
    "    real_values = torch.stack(real_values).cpu()\n",
    "  \n",
    "    return review_texts, predictions, prediction_probs, real_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(model1, test_data_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.811\n"
     ]
    }
   ],
   "source": [
    "print(\"F1 Score:\", \"{:.3f}\".format( metrics.f1_score(y_test, y_pred, labels=None, average='micro')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Prediction on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"My son has Crohn&#039;s disease and has done very well on the Asacol.  He has no complaints and shows no side effects.  He has taken as many as nine tablets per day at one time.  I&#039;ve been very happy with the results, reducing his bouts of diarrhea drastically.\"\n",
      "\n",
      "Predicted sentiment value: 2\n",
      "Predicted sentiment: positive\n",
      "\n",
      "True sentiment value: 2\n",
      "True sentiment: positive\n"
     ]
    }
   ],
   "source": [
    "idx = 1\n",
    "\n",
    "review_text = y_review_texts[idx]\n",
    "true_sentiment = y_test[idx]\n",
    "predicted_sentiment = y_pred[idx]\n",
    "pred_df = pd.DataFrame({\n",
    "  'class_names': class_names,\n",
    "  'values': y_pred_probs[idx]\n",
    "})\n",
    "\n",
    "print(review_text)\n",
    "print()\n",
    "print(\"Predicted sentiment value:\", predicted_sentiment.numpy())\n",
    "print(\"Predicted sentiment:\", class_names[predicted_sentiment])\n",
    "print()\n",
    "print(\"True sentiment value:\", true_sentiment.numpy())\n",
    "print(\"True sentiment:\", class_names[true_sentiment])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"I am a 25 year old female. I was diagnosed with bipolar II disorder about 5 years ago. I have been taking 150mg of lamotrigine for over 2 years. Thus far I have experienced significant improvements in controlling my bipolar II disorder. I recently paired 100mg of sertraline to improve the lows. Also, I experience rapid cycling. I rated this drug 70% as I feel I still have a long way to go in recovery. But, the drug has definitely allowed me to be a highly functioning individual.\"\n",
      "\n",
      "Predicted sentiment value: 2\n",
      "Predicted sentiment: positive\n",
      "\n",
      "True sentiment value: 1\n",
      "True sentiment: neutral\n"
     ]
    }
   ],
   "source": [
    "idx = 29\n",
    "\n",
    "review_text = y_review_texts[idx]\n",
    "true_sentiment = y_test[idx]\n",
    "predicted_sentiment = y_pred[idx]\n",
    "pred_df = pd.DataFrame({\n",
    "  'class_names': class_names,\n",
    "  'values': y_pred_probs[idx]\n",
    "})\n",
    "\n",
    "print(review_text)\n",
    "print()\n",
    "print(\"Predicted sentiment value:\", predicted_sentiment.numpy())\n",
    "print(\"Predicted sentiment:\", class_names[predicted_sentiment])\n",
    "print()\n",
    "print(\"True sentiment value:\", true_sentiment.numpy())\n",
    "print(\"True sentiment:\", class_names[true_sentiment])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment prediction on Raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review text: I need to take many dosages to see the effect. It harms my nervous system and makes me feel more sick. I am not taking it again and will not recommend it to anyone.\n",
      "Sentiment probabilities: tensor([[0.8954, 0.0632, 0.0414]], device='cuda:0', grad_fn=<SoftmaxBackward>)\n",
      "\n",
      "sentiment value: tensor([0], device='cuda:0')\n",
      "Sentiment: negative\n"
     ]
    }
   ],
   "source": [
    "raw_text = 'I need to take many dosages to see the effect. It harms my nervous system and makes me feel more sick. I am not taking it again and will not recommend it to anyone.' \n",
    "\n",
    "encoded_review = tokenizer.encode_plus(\n",
    "  raw_text,\n",
    "  max_length=MAX_LEN,\n",
    "  add_special_tokens=True,\n",
    "  return_token_type_ids=False,\n",
    "  pad_to_max_length=True,\n",
    "  return_attention_mask=True,\n",
    "  return_tensors='pt',\n",
    ")\n",
    "\n",
    "\n",
    "input_ids = encoded_review['input_ids'].to(device)\n",
    "attention_mask = encoded_review['attention_mask'].to(device)\n",
    "\n",
    "pred = model1(input_ids, attention_mask)\n",
    "\n",
    "pred_val = torch.argmax(pred, dim = 1).to(device)\n",
    "probs = F.softmax(pred, dim=1)\n",
    "\n",
    "print(\"Review text:\", raw_text)\n",
    "print(\"Sentiment probabilities:\", probs)\n",
    "print()\n",
    "print(\"sentiment value:\", pred_val)\n",
    "print(\"Sentiment:\", class_names[pred_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
